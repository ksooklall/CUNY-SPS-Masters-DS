---
title: 'Inference for numerical data'
author: ""
output:
  pdf_document: default
  html_document:
    highlight: pygments
    theme: cerulean
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE, message = FALSE, warning = FALSE)
```

## Getting Started

### Load packages

In this lab, we will explore and visualize the data using the **tidyverse** suite of packages, and perform statistical inference using **infer**. The data can be found in the companion package for OpenIntro resources, **openintro**.

Let's load the packages.

```{r load-packages, message=FALSE}
library(tidyverse)
library(openintro)
library(infer)
```


### The data

Every two years, the Centers for Disease Control and Prevention conduct the Youth Risk Behavior Surveillance System (YRBSS) survey, where it takes data from high schoolers (9th through 12th grade), to analyze health patterns. You will work with a selected group of variables from a random sample of observations during one of the years the YRBSS was conducted.

Load the `yrbss` data set into your workspace.

```{r load-data}
data('yrbss', package='openintro')
```

There are observations on 13 different variables, some categorical and some numerical. The meaning of each variable can be found by bringing up the help file:

```{r help-nc, eval=FALSE}
?yrbss
```

### Exercise 1
1.  What are the cases in this data set? How many cases are there in our sample?
The cases are:
helmet_12m, text_while_driving_30d , physically_active_7d, hours_tv_per_school_day, strength_training_7d, school_night_hours_sleep
There are 13583 observations and 13 columns with 6 different cases.

Remember that you can answer this question by viewing the data in the data viewer or by using the following command:

```{r str}
glimpse(yrbss)
```

## Exploratory data analysis

You will first start with analyzing the weight of the participants in kilograms: `weight`.

Using visualization and summary statistics, describe the distribution of weights. The `summary` function can be useful.

```{r summary}
summary(yrbss$weight)
```

### Exercise 2
2.  How many observations are we missing weights from?
There are 1004 missing data in weights columns

Next, consider the possible relationship between a high schooler's weight and their physical activity. Plotting the data is a useful first step because it helps us quickly visualize trends, identify strong associations, and develop research questions.

First, let's create a new variable `physical_3plus`, which will be coded as either "yes" if they are physically active for at least 3 days a week, and "no" if not.

```{r create new var}
yrbss <- yrbss %>% 
  mutate(physical_3plus = ifelse(yrbss$physically_active_7d > 2, "yes", "no"))
```

### Exercise 3
3.  Make a side-by-side boxplot of `physical_3plus` and `weight`. Is there a relationship between these two variables? What did you expect and why?

```{r}
yrbss %>% ggplot(aes(x = physical_3plus, y = weight)) + geom_boxplot()
```

I would expected those who are physically less activate to be on the heavier side; however it looks like the mean for physical_3plus(yes) is higher than (no). The no category has more outliers.

The box plots show how the medians of the two distributions compare, but we can also compare the means of the distributions using the following to first group the data by the `physical_3plus` variable, and then calculate the mean `weight` in these groups using the `mean` function while ignoring missing values by setting the `na.rm` argument to `TRUE`.

```{r by-means}
yrbss %>%
  group_by(physical_3plus) %>%
  summarise(mean_weight = mean(weight, na.rm = TRUE))
```

There is an observed difference, but is this difference statistically significant? In order to answer this question we will conduct a hypothesis test.

## Inference

### Exercise 4
4.  Are all conditions necessary for inference satisfied? Comment on each. You can compute the group sizes with the `summarize` command above by defining a new variable with the definition `n()`.

```{r}
yrbss %>%
  group_by(physical_3plus) %>%
  summarise(mean_weight = mean(weight, na.rm = TRUE), count=n())
```

I think we can drop the NA group since we have no data there and it's also the smallest

### Exercise 5
5.  Write the hypotheses for testing if the average weights are different for those who exercise at least 3 times a week and those who don't.

$H_o: \mu_{exercise} - \mu_{dont-exercise} = 0$
$H_a: \mu_{exercise} - \mu_{dont-exercise} \neq 0$

Next, we will introduce a new function, `hypothesize`, that falls into the `infer` workflow. You will use this method for conducting hypothesis tests. 

But first, we need to initialize the test, which we will save as `obs_diff`.

```{r inf-weight-habit-ht-initial, tidy=FALSE, warning = FALSE}
obs_diff <- yrbss %>%
  specify(weight ~ physical_3plus) %>%
  calculate(stat = "diff in means", order = c("yes", "no"))
```

Notice how you can use the functions `specify` and `calculate` again like you did for calculating confidence intervals. Here, though, the statistic you are searching for is the difference in means, with the order being `yes - no != 0`.

After you have initialized the test, you need to simulate the test on the null distribution, which we will save as `null`.

```{r inf-weight-habit-ht-null, tidy=FALSE, warning = FALSE}
null_dist <- yrbss %>%
  specify(weight ~ physical_3plus) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 1000, type = "permute") %>%
  calculate(stat = "diff in means", order = c("yes", "no"))
```

Here, `hypothesize` is used to set the null hypothesis as a test for independence. In one sample cases, the `null` argument can be set to "point" to test a hypothesis relative to a point estimate.

Also, note that the `type` argument within `generate` is set to `permute`, whichis the argument when generating a null distribution for a hypothesis test.

We can visualize this null distribution with the following code:

```{r}
ggplot(data = null_dist, aes(x = stat)) + geom_histogram()
```

### Exercise 6
6. How many of these `null` permutations have a difference of at least `obs_stat`?

```{r}
nrow(null_dist %>% filter(stat >= obs_diff))
```

None of the null values have a difference of 1.77.

Now that the test is initialized and the null distribution formed, you can calculate the p-value for your hypothesis test using the function `get_p_value`.

```{r inf-weight-habit-ht-pvalue}
null_dist %>%
  get_p_value(obs_stat = obs_diff, direction = "two_sided")
```

This the standard workflow for performing hypothesis tests.

### Exercise 7
7.  Construct and record a confidence interval for the difference between the weights of those who exercise at least three times a week and those who don't, and interpret this interval in context of the data.

```{r}
stats <- yrbss %>%
  group_by(physical_3plus) %>%
  summarise(count = n(),
            means = mean(weight, na.rm = TRUE),
            stdev = sd(weight, na.rm = TRUE)) %>% drop_na()
```

```{r}
s1 = stats$stdev[1]
s2 = stats$stdev[2]
n1 = stats$count[1]
n2 = stats$count[2]

xbar = diff(stats$means)
se = sqrt(s1^2/n1 + s2^2/n2)
t = 1.96
c(xbar - t * se, xbar + t * se)
```

The difference between the weights of those who exercise at least three times a week is between 1.15 and 2.4
* * *

## More Practice

### Exercise 8
8.  Calculate a 95% confidence interval for the average height in meters (`height`) and interpret it in context.

```{r}
heights = yrbss %>% drop_na %>% pull(height)
mn = mean(heights)
stdev = sd(heights)
n = length(heights)
t = 1.96

c(mn - t * stdev / sqrt(n), mn + t * stdev / sqrt(n))
```

The average height is pretty much 1.7, since the range is (1.695 and 1.699) and anything past the second digit isn't necessary when talking about heights.

### Exercise 9
9.  Calculate a new confidence interval for the same parameter at the 90% confidence level. Comment on the width of this interval versus the one obtained in the previous exercise.

```{r}
t = 1.645
c(mn - t * stdev / sqrt(n), mn + t * stdev / sqrt(n))
```

As one would expect, the width get's narrower; however the realistic conclusion would still be the same 1.7

### Exercise 10
10.  Conduct a hypothesis test evaluating whether the average height is different for those who exercise at least three times a week and those who don't.

$H_o: \mu_{height} - \mu_{height_dont-exercise} = 0$
$H_a: \mu_{height} - \mu_{height_dont-exercise} \neq 0$

```{r}
stats <- yrbss %>%
  group_by(physical_3plus) %>%
  summarise(count = n(),
            means = mean(height, na.rm = TRUE),
            stdev = sd(height, na.rm = TRUE)) %>% drop_na()

sy <- stats %>% filter(physical_3plus == 'yes') %>% pull(stdev)
sn <- stats %>% filter(physical_3plus == 'no') %>% pull(stdev)

my <- stats %>% filter(physical_3plus == 'yes') %>% pull(means)
mn <- stats %>% filter(physical_3plus == 'no') %>% pull(means)

ny <- stats %>% filter(physical_3plus == 'yes') %>% pull(count)
nn <- stats %>% filter(physical_3plus == 'no') %>% pull(count)

xbar = my-mn
se = sqrt(sy^2/ny + sn^2/nn)
t = 1.96

c(xbar - t * se, xbar + t * se)
```

### Exercise 11
11.  Now, a non-inference task: Determine the number of different options there are in the dataset for the `hours_tv_per_school_day` there are.

```{r}
count = unique(yrbss$hours_tv_per_school_day)
count
length(count)
```
7 in total with the 8th set of values being NA

### Exercise 12
12. Come up with a research question evaluating the relationship between height or weight and sleep. Formulate the question in a way that it can be answered using a hypothesis test and/or a confidence interval. Report the statistical results, and also provide an explanation in plain language. Be sure to check all assumptions, state your $\alpha$ level, and conclude in context.

Getting more than 5 hrs of sleep is considered good else bad.
I don't believe height has any relationship to the number of hours one sleeps

```{r}
sdf <- yrbss %>% 
  mutate(sleeping=ifelse(yrbss$school_night_hours_sleep %in% c('<5', '5'), 'no', 'yes')) %>% 
  drop_na()

stats <- sdf %>%
          group_by(sleeping) %>%
          summarise(count = n(),
                    means = mean(height, na.rm = TRUE),
                    stdev = sd(height, na.rm = TRUE))

sy <- stats %>% filter(sleeping == 'yes') %>% pull(stdev)
sn <- stats %>% filter(sleeping == 'no') %>% pull(stdev)

my <- stats %>% filter(sleeping == 'yes') %>% pull(means)
mn <- stats %>% filter(sleeping == 'no') %>% pull(means)

ny <- stats %>% filter(sleeping == 'yes') %>% pull(count)
nn <- stats %>% filter(sleeping == 'no') %>% pull(count)

xbar = my-mn
se = sqrt(sy^2/ny + sn^2/nn)
t = 1.96

c(xbar - t * se, xbar + t * se)
```

The 95% confidence interval shows a very small difference
* * *